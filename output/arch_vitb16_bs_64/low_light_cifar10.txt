Use GPU: 3 for training
Initializing the contect with given words: [a_photo_of_a]
Initial context: "a photo of a"
Number of context words (tokens): 4
=> Model created: visual backbone ViT-B/16
=> Using native Torch AMP. Training in mixed precision.
evaluating: low_light_cifar10
['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
=> Acc. on testset [low_light_cifar10-0.01]: @1 17.469999313354492/ @5 59.5
=> Acc. on testset [low_light_cifar10-0.1]: @1 70.08000183105469/ @5 94.22999572753906
=> Acc. on testset [low_light_cifar10-0.25]: @1 86.16999816894531/ @5 98.50999450683594
=> Acc. on testset [low_light_cifar10-0.5]: @1 89.47999572753906/ @5 99.15999603271484
=> Acc. on testset [low_light_cifar10-0.75]: @1 90.22000122070312/ @5 99.3499984741211
=> Acc. on testset [low_light_cifar10-1]: @1 89.93000030517578/ @5 99.29000091552734
=> Acc. on testset [low_light_cifar10-1.25]: @1 88.40999603271484/ @5 98.86000061035156
=> Acc. on testset [low_light_cifar10-1.5]: @1 84.47999572753906/ @5 97.94999694824219
=> Acc. on testset [low_light_cifar10-1.75]: @1 78.72999572753906/ @5 96.41999816894531
=> Acc. on testset [low_light_cifar10-2]: @1 72.48999786376953/ @5 94.63999938964844
======== Result Summary ========
params: nstep	lr	bs
params: 1	0.005	64
		 [set_id] 		 Top-1 acc. 		 Top-5 acc.
low_light_cifar10	

72.49	

