Use GPU: 3 for training
Initializing the contect with given words: [a_photo_of_a]
Initial context: "a photo of a"
Number of context words (tokens): 4
=> Model created: visual backbone RN50
=> Using native Torch AMP. Training in mixed precision.
evaluating: low_light_cifar10
['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
=> Acc. on testset [low_light_cifar10-0.01]: @1 14.949999809265137/ @5 55.209999084472656
=> Acc. on testset [low_light_cifar10-0.1]: @1 32.82999801635742/ @5 80.47000122070312
=> Acc. on testset [low_light_cifar10-0.25]: @1 58.5/ @5 94.23999786376953
=> Acc. on testset [low_light_cifar10-0.5]: @1 69.86000061035156/ @5 97.04999542236328
=> Acc. on testset [low_light_cifar10-0.75]: @1 72.79999542236328/ @5 97.50999450683594
=> Acc. on testset [low_light_cifar10-1]: @1 72.72000122070312/ @5 97.47999572753906
=> Acc. on testset [low_light_cifar10-1.25]: @1 68.52999877929688/ @5 96.33999633789062
=> Acc. on testset [low_light_cifar10-1.5]: @1 61.93000030517578/ @5 94.3699951171875
=> Acc. on testset [low_light_cifar10-1.75]: @1 54.3599967956543/ @5 91.91999816894531
=> Acc. on testset [low_light_cifar10-2]: @1 47.34000015258789/ @5 88.47999572753906
======== Result Summary ========
params: nstep	lr	bs
params: 1	0.005	64
		 [set_id] 		 Top-1 acc. 		 Top-5 acc.
low_light_cifar10	

47.34	

